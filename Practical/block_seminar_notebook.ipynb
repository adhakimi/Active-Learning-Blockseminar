{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1ed6987a704b799884d2d52efc69a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "import torch\n",
    "\n",
    "# Load the Llama-2-7b-chat-hf model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    cache_dir=\"/nfs/datz/olmo_models/al_exp\",\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  GenerationConfig\n",
    "\n",
    "def generate(prompt: str, max_tokens: int = 64, temperature: float = 0.0, **gen_kwargs) -> str:\n",
    "    # Prepare inputs\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    # Generation configuration\n",
    "    gen_config = GenerationConfig(\n",
    "        max_new_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        do_sample=False,\n",
    "        **gen_kwargs\n",
    "    )\n",
    "    # Generate output\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        generation_config=gen_config\n",
    "    )\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Prompting (System + User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a sentiment-analysis assistant. When given a movie review, reply 'Positive' or 'Negative'. Review: 'The cinematography was stunning, but the dialogue felt cheesy.' Label: Positive\n",
      "\n",
      "I would label this review as Positive because the reviewer\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = (\n",
    "    \"You are a sentiment-analysis assistant. When given a movie review, reply 'Positive' or 'Negative'. \"\n",
    "    \"Review: 'The cinematography was stunning, but the dialogue felt cheesy.' Label:\"\n",
    ")\n",
    "print(generate(bad_prompt, max_tokens=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a sentiment-analysis assistant. When given a movie review, reply with exactly one word: 'Positive' or 'Negative'. Do not provide any extra commentary.\n",
      "Review: 'The cinematography was stunning, but the dialogue felt cheesy.'\n",
      "Label: Positive\n"
     ]
    }
   ],
   "source": [
    "system = \"You are a sentiment-analysis assistant. When given a movie review, reply with exactly one word: 'Positive' or 'Negative'. Do not provide any extra commentary.\"\n",
    "user = \"Review: 'The cinematography was stunning, but the dialogue felt cheesy.'\\nLabel:\"\n",
    "good_prompt = system + \"\\n\" + user\n",
    "print(generate(good_prompt, max_tokens=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instruction Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Active learning is a special case of machine learning in which a learning algorithm can interactively query a human user (or some other information source), to label new data points with the desired outputs. The human user must possess knowledge/expertise in the problem domain, including the ability to consult/research authoritative sources when necessary. [1][2][3] In statistics literature, it is sometimes also called optimal experimental design.[4] The information source is also called teacher or oracle.\n",
    "\n",
    "There are situations in which unlabeled data is abundant but manual labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm is overwhelmed by uninformative examples. Recent developments are dedicated to multi-label active learning,[5] hybrid active learning[6] and active learning in a single-pass (on-line) context,[7] combining concepts from the field of machine learning (e.g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning. Using active learning allows for faster development of a machine learning algorithm, when comparative updates would require a quantum or super computer.[8]\n",
    "\n",
    "Large-scale active learning projects may benefit from crowdsourcing frameworks such as Amazon Mechanical Turk that include many humans in the active learning loop.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the text below as bullet points of the most important points. \n",
      "Active learning is a special case of machine learning in which a learning algorithm can interactively query a human user (or some other information source), to label new data points with the desired outputs. The human user must possess knowledge/expertise in the problem domain, including the ability to consult/research authoritative sources when necessary. [1][2][3] In statistics literature, it is sometimes also called optimal experimental design.[4] The information source is also called teacher or oracle.\n",
      "\n",
      "There are situations in which unlabeled data is abundant but manual labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm is overwhelmed by uninformative examples. Recent developments are dedicated to multi-label active learning,[5] hybrid active learning[6] and active learning in a single-pass (on-line) context,[7] combining concepts from the field of machine learning (e.g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning. Using active learning allows for faster development of a machine learning algorithm, when comparative updates would require a quantum or super computer.[8]\n",
      "\n",
      "Large-scale active learning projects may benefit from crowdsourcing frameworks such as Amazon Mechanical Turk that include many humans in the active learning loop.\n",
      "\n",
      "The main advantages of active learning are:\n",
      "\n",
      "* Reduced labeling cost: The cost of labeling data is significantly reduced when the algorithm can select the most informative examples for the user to label.\n",
      "* Improved accuracy: The algorithm can learn more accurately when it is able to select the most informative examples for the user to label.\n",
      "* Faster development: The algorithm can develop faster when it is able to select the most informative examples for the user\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = (\n",
    "    f\"Summarize the text below as bullet points of the most important points. {text}\",\n",
    ")\n",
    "print(generate(bad_prompt, max_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize the text below as a bullet point list of the most important points.\n",
      "\n",
      "    Text: '''\n",
      "Active learning is a special case of machine learning in which a learning algorithm can interactively query a human user (or some other information source), to label new data points with the desired outputs. The human user must possess knowledge/expertise in the problem domain, including the ability to consult/research authoritative sources when necessary. [1][2][3] In statistics literature, it is sometimes also called optimal experimental design.[4] The information source is also called teacher or oracle.\n",
      "\n",
      "There are situations in which unlabeled data is abundant but manual labeling is expensive. In such a scenario, learning algorithms can actively query the user/teacher for labels. This type of iterative supervised learning is called active learning. Since the learner chooses the examples, the number of examples to learn a concept can often be much lower than the number required in normal supervised learning. With this approach, there is a risk that the algorithm is overwhelmed by uninformative examples. Recent developments are dedicated to multi-label active learning,[5] hybrid active learning[6] and active learning in a single-pass (on-line) context,[7] combining concepts from the field of machine learning (e.g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning. Using active learning allows for faster development of a machine learning algorithm, when comparative updates would require a quantum or super computer.[8]\n",
      "\n",
      "Large-scale active learning projects may benefit from crowdsourcing frameworks such as Amazon Mechanical Turk that include many humans in the active learning loop.\n",
      "'''\n",
      "\n",
      "Bullet points:\n",
      "\n",
      "• Active learning is a special case of machine learning that involves interactively querying a human user to label new data points.\n",
      "• The human user must possess knowledge/expertise in the problem domain and can consult/research authoritative sources when necessary.\n",
      "• There are situations where unlabeled data is abundant but manual labeling is expensive, and active learning can be used to query the user for labels.\n",
      "• Active learning can\n"
     ]
    }
   ],
   "source": [
    "good_prompt = (\n",
    "    f\"\"\"Summarize the text below as a bullet point list of the most important points.\\n\n",
    "    Text: '''{text}'''\"\"\"\n",
    ")\n",
    "print(generate(good_prompt, max_tokens=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Detailed, Specific Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a poem about OpenAI.\n",
      "\n",
      "OpenAI, a beacon of light\n",
      "In the realm of AI, a shining sight\n",
      "A place where dreams take flight\n",
      "And innovation reigns supreme tonight\n",
      "\n",
      "Within its walls, a community thrives\n",
      "A gathering of minds, diverse and alive\n",
      "United in their quest for knowledge and might\n",
      "To push the boundaries of what's right\n",
      "\n",
      "From deep learning to reinforcement too\n",
      "OpenAI's research is\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = \"Write a poem about OpenAI.\"\n",
    "print(generate(bad_prompt, max_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a short inspiring poem about OpenAI, focusing on the recent DALL·E product launch (DALL·E is a text-to-image ML model) in the style of Robert Frost, with exactly four lines.\n",
      "\n",
      "In the land of AI, where machines do dream,\n",
      "A new creation blooms, a marvel to gleam.\n",
      "DALL·E, the latest invention, born to please,\n",
      "A world of wonder, with images to tease.\n"
     ]
    }
   ],
   "source": [
    "good_prompt = (\n",
    "    \"Write a short inspiring poem about OpenAI, focusing on the recent DALL·E product launch \"\n",
    "    \"(DALL·E is a text-to-image ML model) in the style of Robert Frost, with exactly four lines.\"\n",
    ")\n",
    "print(generate(good_prompt, max_tokens=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output Format Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the entities mentioned in the text: company names, people names, topics, themes. Text: 'OpenAI announced GPT-4, Sam Altman led the keynote, focusing on AI ethics and future of work.'\n",
      "\n",
      "Entities:\n",
      "\n",
      "* OpenAI\n",
      "* GPT-4\n",
      "* Sam Altman\n",
      "* AI ethics\n",
      "* future of work\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = (\n",
    "    \"Extract the entities mentioned in the text: company names, people names, topics, themes. \"\n",
    "    \"Text: 'OpenAI announced GPT-4, Sam Altman led the keynote, focusing on AI ethics and future of work.'\"\n",
    ")\n",
    "print(generate(bad_prompt, max_tokens=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extract the important entities mentioned in the text below. First extract all company names, then people names, then specific topics, and finally overarching themes.\n",
      "\n",
      "Desired format:\n",
      "Company names: comma-separated-list\n",
      "People names: <comma-separated-list>\n",
      "Specific topics: <comma-separated-list>\n",
      "General themes: <comma-separated-list>\n",
      "\n",
      "Text: 'OpenAI announced GPT-4, Sam Altman led the keynote, focusing on AI ethics and future of work.'\n",
      "\n",
      "Answer:\n",
      "Company names: OpenAI,\n",
      "People names: Sam Altman,\n",
      "Specific topics: AI ethics, future of work,\n",
      "General themes: AI, ethics, work.\n"
     ]
    }
   ],
   "source": [
    "good_prompt = (\n",
    "    \"Extract the important entities mentioned in the text below. First extract all company names, then people names, \"\n",
    "    \"then specific topics, and finally overarching themes.\\n\\n\"\n",
    "    \"Desired format:\\n\"\n",
    "    \"Company names: comma-separated-list\\n\"\n",
    "    \"People names: <comma-separated-list>\\n\"\n",
    "    \"Specific topics: <comma-separated-list>\\n\"\n",
    "    \"General themes: <comma-separated-list>\\n\\n\"\n",
    "    \"Text: 'OpenAI announced GPT-4, Sam Altman led the keynote, focusing on AI ethics and future of work.'\"\n",
    ")\n",
    "print(generate(good_prompt, max_tokens=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Concise, Precise Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The description about Active Learning should be fairly short, a few sentences only, and not too much more.\n",
      "\n",
      "Active learning is a machine learning paradigm that involves actively selecting the most informative instances for training a model, rather than relying on a random or exhaustive sampling approach. By selectively sampling the data, active learning can reduce the amount of labeling required and improve the efficiency of the learning process. Active learning is particularly useful when dealing with large or complex datasets, where the\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = \"The description about Active Learning should be fairly short, a few sentences only, and not too much more.\"\n",
    "print(generate(bad_prompt, max_tokens=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use a 3 to 5 sentence paragraph to describe Active Learning.\n",
      "Active learning is a machine learning paradigm that involves actively engaging with the learning process through querying or interacting with the environment. In contrast to traditional machine learning approaches, which rely on passively receiving labeled data, active learning involves actively seeking out the most informative examples or instances to learn from. This can lead to more efficient learning and improved performance, as the model is able to focus on the most important or challenging cases.\n"
     ]
    }
   ],
   "source": [
    "good_prompt = \"Use a 3 to 5 sentence paragraph to describe Active Learning.\"\n",
    "print(generate(good_prompt, max_tokens=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Instruction Tuning Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label each review as Positive or Negative based on its overall sentiment.\n",
      "Review: 'The movie was okay, but not great.' Label: Negative\n",
      "Review: 'This movie was amazing! The acting was superb and the story was engaging.' Label: Positive\n",
      "Review: 'I didn't like the ending of the movie. It was too predictable\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = (\n",
    "    \"Label each review as Positive or Negative based on its overall sentiment.\\n\"\n",
    "    \"Review: 'The movie was okay, but not great.' Label:\"\n",
    ")\n",
    "print(generate(bad_prompt, max_tokens=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that classifies movie reviews as Positive or Negative.\n",
      "Task: Label each review as 'Positive' or 'Negative' based on its overall sentiment.\n",
      "Review: 'The movie was okay, but not great.'\n",
      "Label: Negative\n",
      "Explanation: Although the reviewer states that the movie was 'okay', the overall sentiment is negative because the reviewer does not express any enthusiasm or excitement about the movie.\n",
      "\n",
      "Review: 'This movie\n"
     ]
    }
   ],
   "source": [
    "system = \"You are a helpful assistant that classifies movie reviews as Positive or Negative.\"\n",
    "task = \"Task: Label each review as 'Positive' or 'Negative' based on its overall sentiment.\"\n",
    "review = \"Review: 'The movie was okay, but not great.'\"\n",
    "good_prompt = system + \"\\n\" + task + \"\\n\" + review + \"\\nLabel:\"\n",
    "print(generate(good_prompt, max_tokens=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. In-Context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Classify the following review as Positive or Negative.\n",
      "Review: 'I found the plot dull and the characters unconvincing.' Label: Negative\n",
      "\n",
      "Explanation: The reviewer found the plot dull\n"
     ]
    }
   ],
   "source": [
    "bad_prompt = (\n",
    "    \"Task: Classify the following review as Positive or Negative.\\n\"\n",
    "    \"Review: 'I found the plot dull and the characters unconvincing.' Label:\"\n",
    ")\n",
    "print(generate(bad_prompt, max_tokens=16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that classifies the sentiment of movie reviews as Positive or Negative.\n",
      "Examples:\n",
      "Review: 'I absolutely loved the acting and the story was gripping.'\n",
      "Label: Positive\n",
      "\n",
      "Review: 'It was a waste of time; plot holes everywhere.'\n",
      "Label: Negative\n",
      "\n",
      "Now classify the following review:\n",
      "Review: 'I found the plot dull and the characters unconvincing.'\n",
      "Label: ___________\n"
     ]
    }
   ],
   "source": [
    "system = \"You are a helpful assistant that classifies the sentiment of movie reviews as Positive or Negative.\"\n",
    "examples = (\n",
    "    \"Review: 'I absolutely loved the acting and the story was gripping.'\\nLabel: Positive\\n\\n\"\n",
    "    \"Review: 'It was a waste of time; plot holes everywhere.'\\nLabel: Negative\\n\\n\"\n",
    ")\n",
    "query = \"Review: 'I found the plot dull and the characters unconvincing.'\\nLabel:\"\n",
    "good_prompt = system + \"\\nExamples:\\n\" + examples + \"Now classify the following review:\\n\" + query\n",
    "print(generate(good_prompt, max_tokens=32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
